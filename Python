import csv
import time
from selenium import webdriver
from selenium.webdriver.edge.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup

def scroll_inside_container(driver, container_selector, pause_time=2, max_scrolls=20):
    scroll_script = """
        var container = document.querySelector(arguments[0]);
        if (!container) return -1;
        container.scrollTop = container.scrollHeight;
        return container.scrollHeight;
    """
    last_height = 0
    for _ in range(max_scrolls):
        new_height = driver.execute_script(scroll_script, container_selector)
        if new_height == -1:
            print(f"Scroll container '{container_selector}' not found.")
            break
        if new_height == last_height:
            break
        last_height = new_height
        time.sleep(pause_time)

def extract_text_cells_same_row(url, class_names, scroll_container_selector, output_csv="output.csv"):
    options = Options()
    options.use_chromium = True
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-gpu')
    # options.add_argument('--headless')  # Optional for visible debug

    driver = webdriver.Edge(options=options)

    try:
        driver.get(url)

        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CLASS_NAME, class_names[0]))
        )

        scroll_inside_container(driver, scroll_container_selector)

        html = driver.page_source

    finally:
        driver.quit()

    soup = BeautifulSoup(html, 'html.parser')
    rows = []

    def extract_texts(div):
        texts = []
        for d in div.find_all('div'):
            text = d.get_text(strip=True)
            if text:
                texts.append(text)
        return texts

    for cls in class_names:
        divs = soup.find_all('div', class_=cls)
        for div in divs:
            row = extract_texts(div)
            if row:
                rows.append(row)

    # Write all rows to CSV
    with open(output_csv, mode='w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerows(rows)

    print(f"\nExported {len(rows)} rows to '{output_csv}'")

# === Config ===
url = "https://example.com"  # Replace with actual URL
class_list = ['Display1', 'Display2', 'Display3']
scroll_container = '.lfcScroll.row.ng-star-inserted'

# Run
extract_text_cells_same_row(url, class_list, scroll_container)
